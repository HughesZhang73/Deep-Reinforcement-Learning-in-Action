# 2.2.3-Softmax选择策略

想象一下另一种类型的多臂强盗问题:一位专门治疗心脏病患者的新医生。她有10种治疗选择，她看到的每个病人只能选择1种治疗。由于某些原因，她只知道这10种治疗方法对心脏病发作有不同的疗效和风险，她还不知道哪一种是最好的。我们可以使用前面解中的n武装的强盗算法，但我们可能需要重新考虑随机选择处理的ε-greedy策略。在这个新问题中，随机选择一种治疗方法可能会导致病人死亡，而不仅仅是损失金钱。我们真的很想确保我们不会选择最糟糕的治疗方法，但我们仍然希望有能力探索我们的选择以找到最好的治疗方法。

这时候使用softmax选项可能是最合适的。与在探索过程中随机选择行动不同，softmax为我们的选择提供了概率分布。概率最大的选项将等同于前一个解决方案中的最佳拉杆动作，但它也会给我们一些关于第二和第三个最佳动作的概念。这样我们就可以随机选择探索其他选项，同时避免最糟糕的选项，因为它们的概率很小，甚至是0。以下是softmax方程式:

![](../../.gitbook/assets/image%20%2853%29.png)

Pr\(A\)是一个函数，它接受动作值向量\(数组\)，并返回动作的概率分布，这样，高值动作的概率就更高。例如，如果你的 action-value 数组有四个可能的动作，它们目前都有相同的值，比如A =\[10,10,10,10\]，那么Pr\(A\) = \[0.25, 0.25, 0.25, 0.25\]。换句话说，所有的概率都是一样的，并且总和必须为1。

分数的分子对动作值数组除以参数τ取幂，生成与输入相同大小\(即长度\)的向量。分母相加除以每一个个体行为值的幂除以τ，得到一个单独的数字。

τ是一个称为温度（temperature）的参数，它缩放了行为的概率分布。 高温将导致概率非常相似，而低温将夸大行动之间的概率差异。为这个参数选择一个值需要有根据的猜测和一些试验和错误。数学指数 e^{x} 是numpy中对np.exp\(…\)的函数调用。这使得函数按元素遍历输入向量。Python中实现softmax函数如下所示：

```text
def softmax(av, tau=1.12):
    softm = np.exp(av / tau) / np.sum(np.exp(av / tau))
    return softm
```

当我们使用softmax实现之前的10个武装强盗问题时，我们不再需要get\_best\_arm函数了。由于softmax在我们可能的行动中产生一个加权概率分布，我们可以根据它们的相对概率随机选择行动。也就是说，我们的最佳行动将被更频繁地选择，因为它将拥有最高的softmax概率，但其他行动将以较低的频率被选择。

为了实现这一点，我们需要做的就是在记录数组的第二列\(列从1开始索引\)上应用**softmax**函数，因为这一列存储了每个操作的当前平均奖励\(动作值\)。它会把这些行为值转化为概率。然后我们用np.random.choice函数,它接受一个任意的输入数组x ,和一个参数p, 概览数组的每个元素和x中每一个元素相关联。因为我们的记录被初始化为0,softmax起初将返回一个均匀分布在多有的拉杆上,但这很快就会斜向分布, 无论动作与最高的奖励时候存在联系。以下是使用softmax和随机选择函数的例子:















