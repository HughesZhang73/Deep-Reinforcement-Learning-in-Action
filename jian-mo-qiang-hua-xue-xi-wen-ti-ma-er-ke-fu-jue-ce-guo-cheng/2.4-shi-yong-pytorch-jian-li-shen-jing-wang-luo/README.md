# 2.4-使用Pytorch 建立神经网络

现在有许多可用的深度学习框架，其中TensorFlow、MXNet和PyTorch可能是最流行的。在本书中，我们选择使用PyTorch是因为它很简单。它允许您编写本地外观的Python代码，同时仍然可以获得良好框架的所有优点，如自动区分和内建优化。我们将在这里向您快速介绍PyTorch，但我们将在接下来的过程中进一步解释。如果你需要温习基本的深度学习，请参阅附录，我们有一个相当详细的回顾深度学习和更全面的PyTorch覆盖。

如果您喜欢numpy多维数组，那么可以用PyTorch替换numpy所做的几乎所有事情。例如，这里我们用numpy实例化一个2×3的矩阵:

```text

import numpy
numpy.array([[1, 2, 3], [4, 5, 6]])

output:
array([[1, 2, 3],
       [4, 5, 6]])
```

```text
import torch
torch.Tensor([[1, 2, 3], [4, 5, 6]])

output:
tensor([[1., 2., 3.],
        [4., 5., 6.]])
```

PyTorch代码与numpy版本基本相同，只是在PyTorch中我们称多维数组为张量 tensors 。不出所料，这也是TensorFlow和其他框架中使用的术语，所以要习惯把多维数组看作张量。我们可以参照张量阶 tensor order ，也就是张量有多少索引维数。这有点令人困惑，因为有时我们说向量的维数，在这种情况下，我们指的是向量的长度。但是当我们说到张量的阶时，我们指的是它有多少个索引。 一个向量有一个索引，这意味着每个元素都可以通过一个索引值“寻址”，所以它是一个1阶张量或简称为1张量。一个矩阵有两个索引，每个维度一个索引，所以它是一个2张量。高阶张量可以称为k- 张量，其中k是阶数，一个非负整数。在另一端，单个数是0张量，也称为标量，因为它没有索引。















































