# 2.3.1-Contextual bandits

也许你可以看到，这只是为我们在本章开始时考虑的n-armed bandit问题增加了一层新的复杂性。在每场比赛中 \(每次顾客在一个特定的网站上结账时\), 我们有n = 10种可能的行动，对应于我们可以投放的10种不同类型的广告。问题在于，最好的广告投放地点可能取决于当前客户在网络的哪个网站上。例如，在我们的珠宝网站上结账的顾客可能更想买一双新鞋搭配他们的新钻石项链，而不是买一台新笔记本电脑。因此，我们的问题是弄清楚一个特定的网站是如何与一个特定的广告相关联的。

这就引出了状态空间**state spaces**。我们开始的n武装的强盗问题有一个n元素的行动空间**action space**\(所有可能的行动的空间或集合\)，但不存在状态的概念。也就是说，环境中没有任何信息可以帮助我们选择一个好的手臂。我们找出哪只手臂是好的唯一方法就是反复试验。在广告问题中，我们知道用户在一个特定的网站上购买东西，**这可能会给我们一些关于用户偏好的信息，并有助于指导我们决定放置哪个广告**。我们将这种上下文信息称为一种状态**state**，并将这种新类型的问题称为上下文**contextual**盗贼\(参见图2.5\)。

![&#x56FE;2.5 &#x5E7F;&#x544A;&#x6295;&#x653E;&#x4E2D;&#x7684;&#x4E0A;&#x4E0B;&#x6587;bandit&#x6982;&#x89C8;](../../.gitbook/assets/image%20%2862%29.png)

{% hint style="info" %}
agent\(神经网络算法\)接收状态信息 \(在这种情况下，当前网站的用户是在\)，它使用选择的几个广告，它应该放置在结帐步骤。 用户会点击或不点击广告，产生奖励信号，反馈给学习代理。
{% endhint %}

{% hint style="success" %}
定义: **state** 游戏中的**状态**\(或者更普遍地说，强化学习问题中的状态\)是环境中可用的一组信息，可以用来做出决策。
{% endhint %}



























