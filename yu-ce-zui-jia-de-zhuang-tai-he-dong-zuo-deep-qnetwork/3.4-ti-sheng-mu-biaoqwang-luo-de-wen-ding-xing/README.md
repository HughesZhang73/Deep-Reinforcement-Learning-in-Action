# 3.4-提升目标Q网络的稳定性

到目前为止，我们已经成功地训练了一种深度强化学习算法来学习和玩《网格世界》，它既有确定性的静态初始化，也有稍微复杂一点的版本，即玩家在每款游戏中被随机放置在棋盘上。不幸的是，尽管算法似乎学会了如何下棋，但很有可能它只是记住了所有可能的棋盘配置，因为4\*4的棋盘相对来说不够复杂。游戏中最困难的变量是玩家、目标、坑和墙都是随机初始化的，这使得算法更难记忆。这应该会促进一些实际的学习，但正如你所看到的，我们在学习这种变体时仍然遇到困难;我们得到了非常嘈杂的损失图。为了帮助解决这个问题，我们将向更新规则添加另一个维度，它将平滑值更新。



