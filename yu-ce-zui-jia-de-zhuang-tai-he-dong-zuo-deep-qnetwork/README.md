# 预测最佳的状态和动作: Deep Q-Network

本章包含以下几个要点:

* 使用神经网络实现 Q 函数
* 使用Pytorch 实现DQN玩Gridworld游戏
* **用经验重放对抗灾难性遗忘**
* **提高目标网络的学习稳定性**

在本章中，我们将从深度强化学习革命的起点开始:DeepMind的深度q网络，它学会了玩雅达利游戏。我们还不会使用雅达利游戏作为我们的测试平台，但我们将创建与DeepMind几乎相同的系统。我们将使用一个简单的基于主机的游戏Grid- world作为我们的游戏环境。

Gridworld》实际上是一款类似的游戏，但它们通常都包含一个带有玩家\(或代理\)的网格面板，一个目标贴图\(“目标”\)，以及可能是障碍或给予消极或积极奖励的一个或多个特殊贴图。 玩家可以向上、向下、向左或向右移动，游戏的重点是让玩家到达目标贴图，在那里玩家将获得积极奖励。玩家不仅要到达目标贴图，还要走最短的路径，他们可能还需要穿越各种障碍。

