---
description: 深度学习基础知识
---

# 深度学习

深度神经网络是由多层更简单的函数组成，称为层\(layer\), 每一个层函数函数由一个矩阵乘法和一个非线性激活函数组成。最常见的激活函数是f\(x\) = max\(0,x\)，如果x为负，则返回0，否则返回x。

一个简单的神经网络如下所示:

![](../../.gitbook/assets/image%20%2821%29.png)

上图从左到右表示,如果数据流从左边进入L1 函数,之后进入L2, 最后输出结果.符号 k , m , n 表示向量的维度.长度为 k 的向量是函数L1的输入,之后产生长度为 m 的向量然后传递给L2, 最终产生一个 n 维的向量.

接下来我们研究下L函数具体做了哪些工作.

![](../../.gitbook/assets/image%20%2823%29.png)

神经网络层一般由两部分组成:矩阵乘法\(matrix multiplication\)和激活函数\(activation function\)。一个长度为n的向量从左边进来，并与一个矩阵\(通常称为参数或权值矩阵\)相乘，这可能改变结果向量的维数。输出的向量维数为 m ，经过非线性激活函数，不会改变向量的维数。

{% hint style="info" %}
 因为矩阵乘法的性质，使用特定维数的矩阵和目标矩阵相乘，可以改变最终矩阵的维数
{% endhint %}

深度神经网络只是将这些层堆叠在一起，我们通过对权重矩阵\(神经网络的参数\)应用梯度下降来训练它。这是Numpy中一个简单的两层神经网络。

```text
# coding=utf-8
import numpy as np


def nn(x, w1, w2):
    l1 = x @ w1  # 矩阵乘法
    l1 = np.maximum(0, l1)  # 非线性激活函数
    
    l2 = l1 @ w2
    l2 = np.maximum(0, l2)
    
    return l2


# 权重（参数）矩阵， 随机初始化
w1 = np.random.randn(784, 200)
w2 = np.random.randn(200, 10)

# 随机输入向量
x = np.random.randn(784)

res = nn(x, w1, w2)
print(res)

'''
result:
[  0.           0.         220.93862853   0.         208.49398735
   0.          92.94278592   0.         603.5514994    0.        ]
'''
```





